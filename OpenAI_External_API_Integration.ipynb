{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-for-Professionals/blob/main/OpenAI_External_API_Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KQD1SXcnSYu",
        "outputId": "9f306642-781c-4511-96fc-f92dd4b5e07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet\n",
        "!pip install ipython --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code."
      ],
      "metadata": {
        "id": "CMs1SliPer2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supported models\n",
        "Not all model versions are trained with function calling data. Function calling is supported with the following models: gpt-4, gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-4-0613, gpt-3.5-turbo, gpt-3.5-turbo-0125, gpt-3.5-turbo-1106, and gpt-3.5-turbo-0613\n",
        "\n",
        "In addition, parallel function calls is supported on the following models: gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and gpt-3.5-turbo-1106"
      ],
      "metadata": {
        "id": "O6voT6dEZOEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from openai import OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-xxxxxxxx\"\n",
        "\n",
        "# Initializing a client object: gets the API Key from environment variable OPENAI_API_KEY\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "qP21QdTRno_A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "owm_api = \"29af1cea50a401d8e624eea4660b3f59\"\n",
        "\n",
        "# create a dummy function to respond temperature\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "  \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\"\n",
        "\n",
        "  url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={owm_api}\"\n",
        "  response = requests.get(url)\n",
        "  temp = response.json()['main']['temp']\n",
        "  forecast = [response.json()['weather'][0]['main'],response.json()['weather'][0]['description']]\n",
        "\n",
        "  weather_info = {\n",
        "      \"location\":location,\n",
        "      \"temperature\":temp,\n",
        "      \"unit\":'Kelvin',\n",
        "      \"forecast\":forecast\n",
        "  }\n",
        "  return json.dumps(weather_info)"
      ],
      "metadata": {
        "id": "FUAVQTH1FCob"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_weather(\"Manila\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zvpewsATGB30",
        "outputId": "1d61f389-d5b9-4345-859a-b107b67f4dc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"location\": \"Manila\", \"temperature\": 303.37, \"unit\": \"Kelvin\", \"forecast\": [\"Clouds\", \"few clouds\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\":\"user\",'content':\"what is AI?\"}]\n",
        "results = client.chat.completions.create(model = \"gpt-3.5-turbo\", messages = messages)\n",
        "results.choices[0].message"
      ],
      "metadata": {
        "id": "6OLj1VFabUCR",
        "outputId": "69bf1c35-0731-4a52-f2db-b859f9a62e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content='AI stands for Artificial Intelligence. It refers to the development of computer systems or machines that can perform tasks that would normally require human intelligence. AI involves the creation of algorithms and models to mimic human cognitive functions such as problem-solving, learning, perception, and decision-making. It encompasses a wide range of technologies, including machine learning, natural language processing, computer vision, and robotics, among others. AI enables computers to analyze large amounts of data, recognize patterns, make predictions, and adapt to changing circumstances, leading to applications in various fields such as healthcare, finance, autonomous vehicles, and virtual assistants.', role='assistant', function_call=None, tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [{\n",
        "                            \"type\":\"function\",\n",
        "                            \"function\":{\"name\": \"get_current_weather\",\n",
        "                           \"description\": \"This function can be used to fetch the current weather information when provided with details such as location and unit for temperature\",\n",
        "                           \"parameters\": {\n",
        "                               \"type\": \"object\",\n",
        "                               \"properties\": {\"location\": {\n",
        "                                   \"type\": \"string\",\n",
        "                                   \"description\": \"The name of city/state/country for which weather information is to be fetched\",},},\n",
        "                               \"required\": [\"location\",],},},}]\n",
        "\n",
        "\n",
        "\n",
        "def get_response(messages, tools,model=\"gpt-3.5-turbo-1106\"):\n",
        "  response = client.chat.completions.create(model = model, messages = messages, tools=tools, tool_choice='auto', temperature=0.5,)\n",
        "  response = response.choices[0].message\n",
        "  tool_calls = response.tool_calls\n",
        "\n",
        "  try:\n",
        "    if tool_calls:\n",
        "      print(\"Making a function call\")\n",
        "      # get available functions\n",
        "      available_functions = {\n",
        "          \"get_current_weather\":get_current_weather,\n",
        "      }\n",
        "      print(tool_calls)\n",
        "\n",
        "      # get details to call the function assuming there is only one function call\n",
        "      func_name = tool_calls[0].function.name\n",
        "      func_to_call = available_functions[func_name]\n",
        "      func_args = json.loads(tool_calls[0].function.arguments)\n",
        "\n",
        "      # call the external api by calling the function\n",
        "      func_response = func_to_call(**func_args)\n",
        "\n",
        "      # again make a call to openai api to communicate results from external function/API\n",
        "      messages.append(response)\n",
        "      messages.append(\n",
        "          {\"tool_call_id\":tool_calls[0].id,\n",
        "          \"role\":\"tool\",\n",
        "          \"name\":func_name,\n",
        "          \"content\":str(func_response)}\n",
        "      )\n",
        "\n",
        "      second_response = client.chat.completions.create(\n",
        "      model = \"gpt-3.5-turbo-1106\",\n",
        "      messages = messages)\n",
        "      return second_response\n",
        "    else:\n",
        "      return response.content\n",
        "  except Exception as e:\n",
        "      print(\"Error occurred \",e)\n",
        "      return response\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9gdvGUJGbheA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Provide a 2 line explanation for AI\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWL0wVqFdeBm",
        "outputId": "2e41cc25-770d-48c6-db0a-d03bca96383d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI (Artificial Intelligence) refers to the simulation of human intelligence in machines that are programmed to think and act like humans. It encompasses a wide range of technologies and applications, including machine learning, natural language processing, and robotics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"How is the weather in Mumbai today?\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0H4DaivdmPW",
        "outputId": "4dbf625c-d1d2-45c7-8c1e-28d2f8e20c9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making a function call\n",
            "[ChatCompletionMessageToolCall(id='call_RD2DF2t561SY5QreaYNWvIzo', function=Function(arguments='{\"location\":\"Mumbai\"}', name='get_current_weather'), type='function')]\n",
            "The weather in Mumbai today is hot with a temperature of 304.14 Kelvin and smoky conditions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OxTpMV2ZczHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}