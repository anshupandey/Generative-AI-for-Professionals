{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-for-Professionals/blob/main/OpenAI_Prompt_Engineering_for_multiple_NLP_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOqg4sAdIedE",
        "outputId": "8e7320b8-89a8-4afa-992b-d2f551404157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet\n",
        "!pip install ipython --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "noj0x1VU6zlA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = \"sk-XXXXXXXXXXXXXXXXXXXXXXXXX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zdh1VZPCUa5a"
      },
      "outputs": [],
      "source": [
        "# Initializing a client object: gets the API Key from environment variable OPENAI_API_KEY\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0WAxkVWZ7LRi"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "\n",
        "def get_output(prompt,model=\"gpt-3.5-turbo\",temperature=0.0,max_tokens=300):\n",
        "  messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLiyOECFIfFL"
      },
      "source": [
        "## Prompt Engineering for Inferense and prediction with ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DDTd9S_KIlZf"
      },
      "outputs": [],
      "source": [
        "review = \"\"\"\n",
        "The HP Envy x360 15 is a premium convertible laptop that offers a perfect blend of performance, portability, and versatility. It's powered by up to an Intel Core i7-13800H processor, 32GB of RAM, and a 1TB SSD, making it a powerhouse that can handle any task you throw at it, from demanding productivity workloads to intensive creative projects and AAA gaming.\n",
        "The Envy x360 15 also features a stunning 15.6-inch touchscreen display with a resolution of 1920x1080 pixels. The display is bright, sharp, and color-accurate, making it ideal for watching movies, editing photos and videos, or simply browsing the web.\n",
        "Thanks to its convertible design, the Envy x360 15 can be used in a variety of different modes, including laptop mode, tablet mode, tent mode, and stand mode. This makes it ideal for students, professionals, and creatives who need a laptop that can adapt to their changing needs.\n",
        "The Envy x360 15 also comes with a number of other premium features, including a backlit keyboard, a fingerprint sensor, a webcam with privacy shutter, Bang & Olufsen speakers, and a variety of ports, including Thunderbolt 4, USB-C, and HDMI.\n",
        "Overall, the HP Envy x360 15 is a fantastic convertible laptop that offers a great combination of performance, portability, versatility, and features. If you're looking for a premium convertible laptop that can do it all, the Envy x360 15 is a great choice.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENZHEK_9Je3r"
      },
      "source": [
        "### Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVT2oDbYJhQW",
        "outputId": "4e608859-b95b-4020-dbeb-9d0d04801451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment for the review is positive.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\" What is the senitment for the below review delimited by triple backticks:\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_HbKtK7JrSl",
        "outputId": "a95b0d84-2b6f-4eb7-e77b-de1a581fc279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\" What is the senitment for the below review delimited by triple backticks.\n",
        "\n",
        "Provide the output as a single word e.g. 'Positive' or 'Negative'\n",
        "\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py8KMLpaKzeT"
      },
      "source": [
        "### Extracting emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTU84XGCKIkn",
        "outputId": "959f4183-902d-4b85-d397-42792d52c1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "excitement, satisfaction, admiration\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Identify a list of emotions the user is expressing while writing the below reivew separated by triple backticks.\n",
        "Provide output as a list of emotions in lowercase separated by comma.\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swDLa36uK0vV"
      },
      "source": [
        "### Identifying anger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7EVWQdzKlip",
        "outputId": "fa7bc729-c206-4c4a-ec92-57cd09d78062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Whether the user is expresssing anger or not in the below reivew separated by triple backticks.\n",
        "Provide output as yes or no\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT14kM8PLOE0"
      },
      "source": [
        "### Entity Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsCg0bm8K-56",
        "outputId": "c802b0e8-c391-43a0-b56f-994d878b8aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"item\": \"HP Envy x360 15\",\n",
            "  \"brand\": \"HP\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the key entities given below from the provided review separated by triple backticks.\n",
        "1. Name of Product mentioned in the review\n",
        "2. Name of company that made the item\n",
        "\n",
        "\n",
        "Provide output as a JSON value, use keys such as 'item' and 'brand'. if the entities are not present, use the word 'unknown' for the value of respective key.\n",
        "keep the result as short as possible.\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZhJV_XkUH2w"
      },
      "source": [
        "### Asking for mulitple info at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZsGoO9DL5my",
        "outputId": "5a967257-d2f1-46c7-c7b5-9e7beba86ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"sentiment\": \"positive\",\n",
            "  \"anger\": \"no\",\n",
            "  \"emotions\": [\"happy\", \"satisfied\"],\n",
            "  \"item\": \"HP Envy x360 15\",\n",
            "  \"brand\": \"HP\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Identify items given below from the provided review separated by triple backticks.\n",
        "1. Sentiment (positive/negative)\n",
        "2. Is user expressing anger (yes/no)\n",
        "3. A list of emotions user is expressing while writing review (lowercase, comma separated, in a list [ ])\n",
        "4. Item purchased by the user\n",
        "5. Name of company that made the item\n",
        "\n",
        "\n",
        "Provide output as a JSON value, use keys such as 'sentiment','anger','emotions','item' and 'brand'. if the entities are not present, use the word 'unknown' for the value of respective key.\n",
        "keep the result as short as possible.\n",
        "Review: ```{review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it-kYeuPUKsg"
      },
      "source": [
        "### Topic Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o44-M3aZT62n"
      },
      "outputs": [],
      "source": [
        "article = \"\"\"\n",
        "Israeli Prime Minister Benjamin Netanyahu urged Elon Musk to strike a balance between protecting free expression and fighting hate speech at a meeting on Monday after weeks of controversy over antisemitic content on Mr. Musk's social media platform X.\n",
        "Earlier this month, Mr. Musk attacked the Anti-Defamation League, accusing the nonprofit that works to fight antisemitism of primarily causing a 60% decrease in U.S. ad revenue at X, without providing evidence.\n",
        "Mr. Musk bought the platform, then known as Twitter, in October.\n",
        "Mr. Musk previously joined a conversation on X with the hashtag #BantheADL, engaging with users who expressed white supremacist views, and asked followers whether he should poll the platform about banning the ADL.\n",
        "\"I hope you find within the confines of the First Amendment, the ability to not only stop antisemitism... but any collective hatred of a people,\" Mr. Netanyahu said during the meeting that was broadcast live on X from Tesla's factory in Fremont, California.\n",
        "\"I know you're committed to that... but I encourage and urge you to find a balance,\" Mr. Netanyahu said.\n",
        "Mr. Musk responded by saying he was against antisemitism and against anything that \"promotes hate and conflict,\" repeating his previous statements that X would not promote hate speech.\n",
        "Mr. Musk has said X should be a platform for people to post diverse viewpoints, but the company will limit the distribution of certain posts that may violate its policies, calling the approach \"freedom of speech, not reach.\"\n",
        "The billionaire, who also runs Tesla and SpaceX, noted that he received more pushback from Tesla employees about the meeting with Mr. Netanyahu than \"anything else I've ever done.\"\n",
        "Mr. Netanyahu and his nationalist-religious coalition are trying to limit some of the Israeli Supreme Court's powers, arguing it is necessary to prevent political overreach by unelected judges.\n",
        "Opponents say the changes could encourage corruption and abuses of power by removing effective oversight, and the issue has split Israeli society and raised concerns over Israel's democratic health.\n",
        "About 200 people protesting the judicial overhaul gathered outside Tesla's California factory, where the event was held.\n",
        "Mr. Musk and Mr. Netanyahu also discussed how to harness the benefits of the rapid advancement of artificial intelligence, while limiting the risks to society, a concern Mr. Musk and others in the tech industry have raised in recent months.\n",
        "\"We stand today at a juncture for all humanity, where we have to choose between a blessing and a curse,\" Mr. Netanyahu said, adding that AI could advance medicine but lead to risks like disrupting democracy.\n",
        "Israel is considered a world-leader in AI, thanks to burgeoning computing and robotics industries that draw on talent developed in the technologically advanced conscript military.\n",
        "Foreign investment in Israeli tech startups has plunged in the last year, partly due to a global slowdown and exacerbated by investor fears that the push to trim the Supreme Court's powers would remove a key check and balance.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNXW7OvvU4ci",
        "outputId": "613fc620-1723-4f69-f6c2-34ceb451603b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "antisemitism, hate speech, social media platform, Israeli Supreme Court, artificial intelligence\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the 5 key topics which are being discussed in the below reivew separated by triple backticks.\n",
        "Make each item no longer than one or two words.\n",
        "\n",
        "Provide output list of topics, lowercase, comma separated\n",
        "Review: ```{article}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi-IhWDyVavb"
      },
      "source": [
        "### Language Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqzlvNLkVPjG",
        "outputId": "959b40ce-0110-40b6-ab12-8c761499f307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```Halo, Apa kabar?```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Translate below text into indonesian separated by triple backticks.\n",
        "Text: ```Hello, How are you?```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVfG0IsVVrgA",
        "outputId": "eceb104e-c73a-4146-838d-2855e130b6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```Bonjour, comment ça va ?```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Translate below text into french separated by triple backticks.\n",
        "Text: ```Hello, How are you?```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz0GVTVsVv1F",
        "outputId": "8a44ec5f-bcae-409e-d632-9dd519c1abc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The language for the text \"Terima Kasih\" is Indonesian.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the language for the text separated by triple backticks.\n",
        "Text: ```Terima Kasih```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AbYP_jZV416",
        "outputId": "904347af-0d76-4480-e8a3-3f5ef891035e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "French: ```Bonjour, comment ça va?```\n",
            "Hindi: ```नमस्ते, आप कैसे हैं?```\n",
            "Arabic: ```مرحبًا، كيف حالك؟```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Translate below text into french, hindi and arabic separated by triple backticks.\n",
        "Text: ```Hello, How are you?```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-sF3VyOWBwu",
        "outputId": "c4aaace9-939b-4449-fcb2-50edd2e8f511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formal: ```Selamat sejahtera, Apa khabar?```\n",
            "\n",
            "Informal: ```Hai, Apa khabar?```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Translate below text into malay both in formal and informal way separated by triple backticks.\n",
        "Text: ```Hello, How are you?```\n",
        "\"\"\"\n",
        "\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAkIjn9ob6su"
      },
      "source": [
        "### TOne transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru54muMAWOCh",
        "outputId": "7d1459d7-3a1d-4a6f-fd84-834e6234fd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Your Name]\n",
            "[Your Title]\n",
            "[Your Company]\n",
            "[Your Address]\n",
            "[City, State, ZIP]\n",
            "[Email Address]\n",
            "[Phone Number]\n",
            "[Date]\n",
            "\n",
            "[Recipient's Name]\n",
            "[Recipient's Title]\n",
            "[Recipient's Company]\n",
            "[Recipient's Address]\n",
            "[City, State, ZIP]\n",
            "\n",
            "Dear [Recipient's Name],\n",
            "\n",
            "I hope this letter finds you well. I wanted to bring to your attention the recent integration at OpenAI API, which I believe is truly remarkable. The advancements made by these individuals are nothing short of amazing.\n",
            "\n",
            "The integration at OpenAI API has introduced a range of cool features that have the potential to revolutionize our industry. The team behind this development has showcased their exceptional skills and dedication to pushing the boundaries of technology.\n",
            "\n",
            "As a business that values innovation and staying at the forefront of advancements, I thought it was important to share this exciting news with you. The integration at OpenAI API presents us with new opportunities and possibilities that we should explore together.\n",
            "\n",
            "I would be delighted to discuss this further and explore how we can leverage this advancement to benefit our own business. Please let me know if you would be available for a meeting or a call at your convenience.\n",
            "\n",
            "Thank you for your time, and I look forward to hearing from you soon.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Your Company]\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Translate the following text into a business letter:\n",
        " Hey bob, look at the recent integration at openai api, these guys are amazing, such a cool advancement man!.\n",
        "\"\"\"\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6GLCIBlcmG2"
      },
      "source": [
        "### Format conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxkWiJoCcXRq"
      },
      "outputs": [],
      "source": [
        "data_json = {\"Cognizant employees\":[\n",
        "    {\"name\":\"Axex\",\"email\":\"alex@cog.com\"}, {\"name\":\"Arturo\",\"email\":\"arturo@cog.com\"},  {\"name\":\"Kanchan\",\"email\":\"kanchan@cog.com\"},\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary  from JSON to an HTML table with column headers and title:{data_json}\n",
        "If you are using CSS, consider the contrast between background and text color\n",
        "\"\"\"\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otwi-oYCdTLk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display,HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrYUMzMtdO5T"
      },
      "outputs": [],
      "source": [
        "display(HTML(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk_b6sBDdnx5",
        "outputId": "1a5fd5ee-6141-43f8-a8a1-94ea1ae67006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got this for my daughter for her birthday because she keeps taking mine from my room. Yes, adults also like pandas too. She takes it everywhere with her, and it's super soft and cute. However, one of the ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. Additionally, it's a bit small for what I paid for it. I believe there might be other options that are bigger for the same price. On the positive side, it arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking mine from my room.  Yes, adults also like pandas too.  She takes it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was designed to be asymmetrical. It's a bit small for what I paid for it though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"\"\" proofread and correct this review: ```{text}```\n",
        "\"\"\"\n",
        "response = get_output(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4q4Ca9ge6_q"
      },
      "outputs": [],
      "source": [
        "!pip install redlines --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An28b2ysej5M"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import Markdown\n",
        "from redlines import Redlines\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GHnJWeqe57l",
        "outputId": "550f6727-1b9a-4da4-87f0-e168fbb8ebf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got this adorable panda plush toy for my daughter as a birthday gift because she constantly takes mine from my room. It's worth mentioning that adults can also appreciate the charm of pandas. This plush toy has become her constant companion, accompanying her everywhere she goes. The material is incredibly soft and the design is undeniably cute. However, I did notice that one of the ears is slightly lower than the other, which seems unintentional as it lacks symmetry. Additionally, considering the price I paid, I find the size to be a bit small. It's possible that there are other options available at the same price point that offer a larger size. On a positive note, the delivery was prompt, arriving a day earlier than expected. This allowed me to enjoy playing with the plush toy myself before presenting it to my daughter.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "proofread and correct this review delimited by triple backticks.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Provide the output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_output(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "ELS16o31fQG8",
        "outputId": "834f7ed8-5368-4c98-99c1-887cf543f383"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Got this <span style='color:green;font-weight:700;'>adorable panda plush toy </span>for my daughter <span style='color:red;font-weight:700;text-decoration:line-through;'>for her </span><span style='color:green;font-weight:700;'>as a </span>birthday <span style='color:red;font-weight:700;text-decoration:line-through;'>cuz </span><span style='color:green;font-weight:700;'>gift because </span>she <span style='color:red;font-weight:700;text-decoration:line-through;'>keeps taking </span><span style='color:green;font-weight:700;'>constantly takes </span>mine from my <span style='color:red;font-weight:700;text-decoration:line-through;'>room.  Yes, </span><span style='color:green;font-weight:700;'>room. It's worth mentioning that </span>adults <span style='color:green;font-weight:700;'>can </span>also <span style='color:red;font-weight:700;text-decoration:line-through;'>like pandas too.  She takes it </span><span style='color:green;font-weight:700;'>appreciate the charm of pandas. This plush toy has become her constant companion, accompanying her </span>everywhere <span style='color:red;font-weight:700;text-decoration:line-through;'>with her, and it's super </span><span style='color:green;font-weight:700;'>she goes. The material is incredibly </span>soft and <span style='color:red;font-weight:700;text-decoration:line-through;'>cute.  One </span><span style='color:green;font-weight:700;'>the design is undeniably cute. However, I did notice that one </span>of the ears is <span style='color:red;font-weight:700;text-decoration:line-through;'>a bit </span><span style='color:green;font-weight:700;'>slightly </span>lower than the other, <span style='color:red;font-weight:700;text-decoration:line-through;'>and </span><span style='color:green;font-weight:700;'>which seems unintentional as it lacks symmetry. Additionally, considering the price </span>I <span style='color:red;font-weight:700;text-decoration:line-through;'>don't think that was designed </span><span style='color:green;font-weight:700;'>paid, I find the size </span>to be <span style='color:red;font-weight:700;text-decoration:line-through;'>asymmetrical. It's </span>a bit <span style='color:red;font-weight:700;text-decoration:line-through;'>small for what I paid for it though. I think </span><span style='color:green;font-weight:700;'>small. It's possible that </span>there <span style='color:red;font-weight:700;text-decoration:line-through;'>might be </span><span style='color:green;font-weight:700;'>are </span>other options <span style='color:red;font-weight:700;text-decoration:line-through;'>that are bigger for </span><span style='color:green;font-weight:700;'>available at </span>the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  It arrived </span><span style='color:green;font-weight:700;'>price point that offer a larger size. On a positive note, the delivery was prompt, arriving </span>a day earlier than <span style='color:red;font-weight:700;text-decoration:line-through;'>expected, so I got </span><span style='color:green;font-weight:700;'>expected. This allowed me </span>to <span style='color:red;font-weight:700;text-decoration:line-through;'>play </span><span style='color:green;font-weight:700;'>enjoy playing </span>with <span style='color:red;font-weight:700;text-decoration:line-through;'>it </span><span style='color:green;font-weight:700;'>the plush toy </span>myself before <span style='color:red;font-weight:700;text-decoration:line-through;'>I gave </span><span style='color:green;font-weight:700;'>presenting </span>it to my daughter."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import Markdown\n",
        "from redlines import Redlines\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVdvwN5MfTgM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}