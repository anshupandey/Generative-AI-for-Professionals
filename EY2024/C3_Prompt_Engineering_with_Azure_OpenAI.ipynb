{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-for-Professionals/blob/main/EY2024/C3_Prompt_Engineering_with_Azure_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZBMUH466r3l"
      },
      "source": [
        "# Azure openAI : Prompt Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE8b9M1Ubhwy"
      },
      "source": [
        "### Prompt Engineering\n",
        "\n",
        "Prompt engineering is the process of designing and optimizing prompts to better utilize LLMs. Designing effective prompts is critical to the success of prompt engineering, and it can significantly improve the AI model's performance on specific tasks. Providing relevant, specific, unambiguous, and well structured prompts can help the model better understand the context and generate more accurate responses.\n",
        "\n",
        "For example, if we want an OpenAI model to generate product descriptions, we can provide it with a detailed description that describes the features and benefits of the product. By providing this context, the model can generate more accurate and relevant product descriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAM4eBWgbhwz"
      },
      "source": [
        "**Let's start with Azure openAI**\n",
        "\n",
        "Create an Azure OpenAI resource with the following settings:\n",
        "\n",
        "        Subscription: Select an Azure subscription that has been approved for access to the Azure OpenAI service\n",
        "        Resource group: Choose or create a resource group\n",
        "        Region: Make a random choice from any of the available regions*\n",
        "        Name: A unique name of your choice\n",
        "        Pricing tier: Standard S0\n",
        "\n",
        "\n",
        "Wait for deployment to complete. Then go to the deployed Azure OpenAI resource in the Azure portal.\n",
        "\n",
        "\n",
        "\n",
        "**Deploy a model**\n",
        "\n",
        "Azure OpenAI provides a web-based portal named Azure OpenAI Studio, that you can use to deploy, manage, and explore models. You'll start your exploration of Azure OpenAI by using Azure OpenAI Studio to deploy a model.\n",
        "\n",
        "1. On the Overview page for your Azure OpenAI resource, use the Go to Azure OpenAI Studio button to open Azure OpenAI Studio in a new browser tab.\n",
        "\n",
        "2. In Azure OpenAI Studio, on the Deployments page, view your existing model deployments. If you don't already have one, create a new deployment of the gpt-35-turbo-16k model with the following settings:\n",
        "\n",
        "        Model: gpt-35-turbo-16k (if the 16k model isn't available, choose gpt-35-turbo)\n",
        "        Model version: Auto-update to default\n",
        "        Deployment name: A unique name of your choice\n",
        "        Advanced options\n",
        "        Content filter: Default\n",
        "        Tokens per minute rate limit: 5K*\n",
        "        Enable dynamic quota: Enabled\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Explore prompt engineering techniques**\n",
        "\n",
        "Let's start by exploring some prompt engineering techniques in the Chat playground.\n",
        "\n",
        "1. In Azure OpenAI Studio, in the Playground section, select the Chat page. The Chat playground page consists of three main sections:\n",
        "\n",
        "        Assistant setup - used to set the context for the model's responses.\n",
        "        Chat session - used to submit chat messages and view responses.\n",
        "        Configuration - used to configure settings for the model deployment.\n",
        "\n",
        "2. In the Configuration section, ensure that your model deployment is selected.\n",
        "\n",
        "3. In the Assistant setup area, select the default system message template to set the context for the chat session. The default system message is You are an AI assistant that helps people find information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS0UYV6Sbhwz"
      },
      "source": [
        "#### Example 1\n",
        "\n",
        "Try:\n",
        "\n",
        "    What kind of article is this?\n",
        "    ---\n",
        "    Severe drought likely in California\n",
        "\n",
        "    Millions of California residents are bracing for less water and dry lawns as drought threatens to leave a large swath of the region with a growing water shortage.\n",
        "\n",
        "    In a remarkable indication of drought severity, officials in Southern California have declared a first-of-its-kind action limiting outdoor water use to one day a week for nearly 8 million residents.\n",
        "\n",
        "    Much remains to be determined about how daily life will change as people adjust to a drier normal. But officials are warning the situation is dire and could lead to even more severe limits later in the year.\n",
        "\n",
        "\n",
        "\n",
        "Now:\n",
        "\n",
        "In the Assistant setup section change the system message to\n",
        "\n",
        "        You are a news aggregator that categorizes news articles.\n",
        "\n",
        "Under the new system message, select the Add an example button. Add the following example.\n",
        "\n",
        "\n",
        "User:\n",
        "\n",
        "\n",
        "    What kind of article is this?\n",
        "    ---\n",
        "    New York Baseballers Wins Big Against Chicago\n",
        "\n",
        "    New York Baseballers mounted a big 5-0 shutout against the Chicago Cyclones last night, solidifying their win with a 3 run homerun late in the bottom of the 7th inning.\n",
        "\n",
        "    Pitcher Mario Rogers threw 96 pitches with only two hits for New York, marking his best performance this year.\n",
        "\n",
        "    The Chicago Cyclones' two hits came in the 2nd and the 5th innings but were unable to get the runner home to score.\n",
        "\n",
        "\n",
        "Assistant:\n",
        "\n",
        "    Sports\n",
        "\n",
        "\n",
        "\n",
        "Add another example with the following text.\n",
        "\n",
        "User:\n",
        "\n",
        "    Categorize this article:\n",
        "    ---\n",
        "    Joyous moments at the Oscars\n",
        "\n",
        "    The Oscars this past week where quite something!\n",
        "\n",
        "    Though a certain scandal might have stolen the show, this year's Academy Awards were full of moments that filled us with joy and even moved us to tears.\n",
        "    These actors and actresses delivered some truly emotional performances, along with some great laughs, to get us through the winter.\n",
        "\n",
        "    From Robin Kline's history-making win to a full performance by none other than Casey Jensen herself, don't miss tomorrows rerun of all the festivities.\n",
        "\n",
        "\n",
        "Assistant:\n",
        "\n",
        "    Entertainment\n",
        "\n",
        "Use the Save changes button at the top of the Assistent setup section to update the system message.\n",
        "\n",
        "In the Chat session section, resubmit the following prompt:\n",
        "\n",
        "    What kind of article is this?\n",
        "    ---\n",
        "    Severe drought likely in California\n",
        "\n",
        "    Millions of California residents are bracing for less water and dry lawns as drought threatens to leave a large swath of the region with a growing water shortage.\n",
        "\n",
        "    In a remarkable indication of drought severity, officials in Southern California have declared a first-of-its-kind action limiting outdoor water use to one day a week for nearly 8 million residents.\n",
        "\n",
        "    Much remains to be determined about how daily life will change as people adjust to a drier normal. But officials are warning the situation is dire and could lead to even more severe limits later in the year.\n",
        "    The combination of a more specific system message and some examples of expected queries and responses results in a consistant format for the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zF2qmQJbhwz"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "In the Assistant setup section, change the system message back to the default template, which should be\n",
        "\n",
        "    You are an AI assistant that helps people find information. with no examples.\n",
        "    \n",
        "Then save the changes.\n",
        "\n",
        "In the Chat session section, submit the following prompt:\n",
        "\n",
        "    # 1. Create a list of animals\n",
        "    # 2. Create a list of whimsical names for those animals\n",
        "    # 3. Combine them randomly into a list of 25 animal and name pairs\n",
        "\n",
        "The model will likely respond with an answer to satisfy the prompt, split into a numbered list.\n",
        "\n",
        "\n",
        "This is an appropriate response, but suppose what you actually wanted was for the model to write a Python program that performs the tasks you described?\n",
        "\n",
        "Change the system message to\n",
        "    \n",
        "    You are a coding assistant helping write python code. and click Save changes\n",
        "\n",
        "Resubmit the following prompt to the model:\n",
        "\n",
        "    # 1. Create a list of animals\n",
        "    # 2. Create a list of whimsical names for those animals\n",
        "    # 3. Combine them randomly into a list of 25 animal and name pairs\n",
        "The model should correctly respond with python code doing what the comments requested."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB85L9Fs6jMM"
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noj0x1VU6zlA"
      },
      "outputs": [],
      "source": [
        "api_key = \"xxxxxxxxxxxxxxxx\"\n",
        "api_version = \"2023-07-01-preview\" # \"2023-05-15\"\n",
        "azure_endpoint = \"https://xxxxxxxxxxx.openai.azure.com/\"\n",
        "deployment_name = \"xxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2ZmO49Xbhw0"
      },
      "outputs": [],
      "source": [
        "from openai import AzureOpenAI\n",
        "\n",
        "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
        "client = AzureOpenAI(\n",
        "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
        "    api_version=api_version,\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_key = api_key,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTy9qlaNbhw1",
        "outputId": "2c32b2eb-d3d1-4329-9f0e-2d27f90b2baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9azCTlkFr0i5pJox17WAIFmsOJIjm\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"You can use the os module in Python to output all files in a directory. Here's an example code that demonstrates how to do this:\\n\\n```python\\nimport os\\n\\ndirectory = \\\"/path/to/your/directory\\\"\\n\\n# List all files in the directory\\nfiles = os.listdir(directory)\\n\\n# Output all files in the directory\\nfor file in files:\\n    print(file)\\n```\\n\\nReplace \\\"/path/to/your/directory\\\" with the actual path to your directory. This code will list all the files in the specified directory and then output each file name.\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1718602089,\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": \"fp_811936bd4f\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 112,\n",
            "    \"prompt_tokens\": 19,\n",
            "    \"total_tokens\": 131\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "result = client.chat.completions.create(\n",
        "    model=deployment_name,  # e.g. gpt-35-instant\n",
        "    max_tokens=500,\n",
        "    temperature=0.9,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How do I output all files in a directory using Python?\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "print(result.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcbHv2PJbhw1",
        "outputId": "0ad2670a-884d-4869-9bfa-bccc71b41cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You can use the os module in Python to output all files in a directory. Here's an example code that demonstrates how to do this:\n",
            "\n",
            "```python\n",
            "import os\n",
            "\n",
            "directory = \"/path/to/your/directory\"\n",
            "\n",
            "# List all files in the directory\n",
            "files = os.listdir(directory)\n",
            "\n",
            "# Output all files in the directory\n",
            "for file in files:\n",
            "    print(file)\n",
            "```\n",
            "\n",
            "Replace \"/path/to/your/directory\" with the actual path to your directory. This code will list all the files in the specified directory and then output each file name.\n"
          ]
        }
      ],
      "source": [
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WAxkVWZ7LRi"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(prompt,model=deployment_name,temperature=0):\n",
        "  messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=temperature\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tLgNfQbz7xpQ",
        "outputId": "c4cd65e2-dd28-49b6-ecbf-efb48d0c0e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "print('Hello World')\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = generate_response(\"Write a python code to print 'Hello World'\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZcaHAuU94x0"
      },
      "source": [
        "## Experimenting with different values of temperature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMwThtKC94x0",
        "outputId": "bc7df408-536f-4083-8d88-2fc3b95560ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vibrant culture, delicious food, and rich history.\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "vibrant culture, delicious food, and rich history.\n",
            "vibrant culture, delicious food, and rich history.\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "vibrant culture, delicious food, and rich history.\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "vibrant culture, delicious food, and rich history.\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    response = generate_response(prompt=\"complete the following sentence: \\n\\n 'I am visiting Manila, its is a city of '\",\n",
        "                                 temperature=0)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfGFmz4K94x0",
        "outputId": "9dfe2a2c-cc8b-49c3-928d-a90d9eaf6f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At Temperature: 0\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "************************************************************\n",
            "At Temperature: 0.4\n",
            "vibrant culture, delicious food, and bustling energy.\n",
            "************************************************************\n",
            "At Temperature: 0.8\n",
            "vibrant culture, delicious food, and beautiful historical landmarks.\n",
            "************************************************************\n",
            "At Temperature: 1.2\n",
            "contrasts where modern skyscrapers stand next to historical landmarks and bustling markets.\n",
            "************************************************************\n",
            "At Temperature: 1.5\n",
            " high energy and bustling activity, vibrant culture, and exciting opportunities.\n",
            "************************************************************\n",
            "At Temperature: 1.8\n",
            "vibrant cultural heritage, distinctive cuisine, and a bustling urban energy.\n",
            "************************************************************\n",
            "At Temperature: 2.0\n",
            " vibrant lifestyle, historical charm, and delicious cuisine.\n",
            "************************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tvalues = [0,0.4,0.8,1.2,1.5,1.8,2.0]\n",
        "for i in range(len(tvalues)):\n",
        "    response = generate_response(prompt=\"complete the following sentence: \\n\\n 'I am visiting Manila, its is a city of '\",\n",
        "                                 temperature=tvalues[i])\n",
        "    print(f\"At Temperature: {tvalues[i]}\")\n",
        "    print(response)\n",
        "    print(\"***\"*20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij40o9G0ESfg"
      },
      "source": [
        "# Key guidelines for prompt engineering\n",
        "\n",
        "1. CCS: Clear, Concise and Specific instructions\n",
        "\n",
        "      a. Use proper delimeters\n",
        "          - Triple Quotes \"\"\"\n",
        "          - Triple backticks ```\n",
        "          - Triple Dashes ---\n",
        "          - Angle bracket <>\n",
        "          - xml tags \"< start> < /start>\"\n",
        "\n",
        "      b. be structured in content: Use Persona, Task, constraints, output format\n",
        "\n",
        "  \n",
        "2. Give the model time to think\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyGpCUafNffB"
      },
      "source": [
        "## component 1: Use proper delimeters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSkCESQV7-Iw",
        "outputId": "ae825aa2-5519-4754-ab96-ebe728bdfc2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nSummarize the text delimited by triple backticks into a single sentence.\\n```\\nNorth Korean leader Kim Jong Un, currently visiting Russia, inspected several state-of-the-art systems deployed in the ongoing Ukraine war, including the Kinzhal hypersonic missile, supersonic bombers, and the latest weapons mounted on the MiG-31 missile carrier.\\nThis information was published by the Russian Ministry of Defense (RuMoD) on its official Telegram channel. The inspection of the next-generation missile system was also accompanied by a meeting with Russian Defense Minister Sergei Shoigu at the Knevichi airfield near Vladivostok in the Far East of Russia.\\n“At the Knevichi airfield, Russian Minister of Defense General of the Army Sergei Shoigu presented the Russian MiG-31I missile carrier with the latest weaponry – the Kinzhal hypersonic air-launched missile – to the leader of the Democratic People’s Republic of Korea Kim Jong-un,” the RuMoD said in a statement on Telegram.\\nBriefing the North Korean leader, Commander of the Long-Range Aviation of the Russian Aerospace Forces Lieutenant General Sergei Kobylash reported on the flight and technical characteristics of the Kinzhal hypersonic missile system. On top of that, he noted that the system includes a Mig-31I missile carrier equipped with the Kinzhal hypersonic aero-ballistic missile and a missile control system.\\n“This Russian aircraft system has no equivalent anywhere in the world and has shown to be very combat-effective,” the Russian MoD said in a statement emphasizing the deadly combination of MiG-31 and the Kinzhal hypersonic missiles. Russia has fired these missiles, touted as invincible by Russia, on Ukrainian targets several times during this bloody conflict.\\nAs he spoke with Shoigu and other military officials through interpreters about technical specifics, Kim looked at the Kinzhal missile, gestured, and asked questions about the jets’ capabilities.\\nThe inspection is significant as it comes amid heightened concerns in the West about a potential arms agreement that will be signed between the two of its adversaries, which have been inching closer to each other since the Russian invasion led to Moscow’s isolation.\\nhttps://twitter.com/i/status/1703110950822293981\\nWestern commentators believe Kim’s visit to Russia’s military and technical installations may have hinted at what he wants from Russia in return for giving ammunition to top off Putin’s depleting supplies. However, there is no information as to what systems the North Korean President would be interested in if an arms agreement is indeed in the works.\\nAccording to experts, prospective military cooperation between the two nations may entail initiatives to update North Korea’s obsolete air force, which was still dependent on jets from the Soviet Union in the 1980s. However, experts also believe that the Kinzhal and the MiG-31 inspection do not automatically translate into a deal.\\nKh-47M2 Kinzhal - Wikipedia\\nIndian Air Force veteran and military expert who keenly watches the Russian military, Squadron Leader Vijainder K. Thakur (retd.), explained to EurAsian Times, “Kinzhal is not just a missile that you can shoot at the adversary. It needs a launch platform that is expensive and difficult to operate. It needs intelligence for targeting. North Korea does not have MiG-31D. Since the heavy fighter is not in production, it is very doubtful that Russia can transfer it to North Korea.”\\nWhen it was pointed out that Russia is reportedly firing the Kinzhal from its Su-34 Fullback fighter bomber, Thakur retorted, “North Korea does not have Su 34. Russia has as yet not met its demand for its Su-34 frontline bomber. So, it is improbable.”\\nThe US has accused Kim of supplying weapons and ammunition, including shells and rockets, to support Putin’s conflict for months. Although the US claims that the guns won’t dramatically change the battlefield, they can still be used to shell Ukraine. More importantly, these sales could give North Korea a new source of income for a country whose economy is mainly cut off from international trade.\\nSome officials in the US as well as South Korea have warned that any such deal would be in contravention of the UN sanctions and would come at a heavy price.\\nCutting-Edge Systems Shown To North Korean Leader\\nThe North Korean leader was also shown an array of cutting-edge warplanes, out of which its strategic supersonic bombers particularly stood out. Bombers like Tu-160, Tu-95, and Tu-22 bombers that have been extensively deployed to launch cruise missiles were presented to Kim Jong Un.\\nIn addition, Kim was informed by Shoigu and Lt. Gen. Sergei Kobylash that the Tu-160 had just acquired brand-new cruise missiles with a 4,040-mile range. Shoigu pointed to the weapons bay and stated that each bomber had 12 missiles.\\nBesides the bombers, Kim also had the chance to see Russia’s fifth-generation stealth jet. The RuMoD noted that Kim also visited the Russian Marshal Shaposhnikov frigate to inspect the Su-35 and the Su-57 stealth combat fighter during a tour of a factory producing fighter jets and other aircraft types.\\n```\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "text = \"\"\"\n",
        "North Korean leader Kim Jong Un, currently visiting Russia, inspected several state-of-the-art systems deployed in the ongoing Ukraine war, including the Kinzhal hypersonic missile, supersonic bombers, and the latest weapons mounted on the MiG-31 missile carrier.\n",
        "This information was published by the Russian Ministry of Defense (RuMoD) on its official Telegram channel. The inspection of the next-generation missile system was also accompanied by a meeting with Russian Defense Minister Sergei Shoigu at the Knevichi airfield near Vladivostok in the Far East of Russia.\n",
        "“At the Knevichi airfield, Russian Minister of Defense General of the Army Sergei Shoigu presented the Russian MiG-31I missile carrier with the latest weaponry – the Kinzhal hypersonic air-launched missile – to the leader of the Democratic People’s Republic of Korea Kim Jong-un,” the RuMoD said in a statement on Telegram.\n",
        "Briefing the North Korean leader, Commander of the Long-Range Aviation of the Russian Aerospace Forces Lieutenant General Sergei Kobylash reported on the flight and technical characteristics of the Kinzhal hypersonic missile system. On top of that, he noted that the system includes a Mig-31I missile carrier equipped with the Kinzhal hypersonic aero-ballistic missile and a missile control system.\n",
        "“This Russian aircraft system has no equivalent anywhere in the world and has shown to be very combat-effective,” the Russian MoD said in a statement emphasizing the deadly combination of MiG-31 and the Kinzhal hypersonic missiles. Russia has fired these missiles, touted as invincible by Russia, on Ukrainian targets several times during this bloody conflict.\n",
        "As he spoke with Shoigu and other military officials through interpreters about technical specifics, Kim looked at the Kinzhal missile, gestured, and asked questions about the jets’ capabilities.\n",
        "The inspection is significant as it comes amid heightened concerns in the West about a potential arms agreement that will be signed between the two of its adversaries, which have been inching closer to each other since the Russian invasion led to Moscow’s isolation.\n",
        "https://twitter.com/i/status/1703110950822293981\n",
        "Western commentators believe Kim’s visit to Russia’s military and technical installations may have hinted at what he wants from Russia in return for giving ammunition to top off Putin’s depleting supplies. However, there is no information as to what systems the North Korean President would be interested in if an arms agreement is indeed in the works.\n",
        "According to experts, prospective military cooperation between the two nations may entail initiatives to update North Korea’s obsolete air force, which was still dependent on jets from the Soviet Union in the 1980s. However, experts also believe that the Kinzhal and the MiG-31 inspection do not automatically translate into a deal.\n",
        "Kh-47M2 Kinzhal - Wikipedia\n",
        "Indian Air Force veteran and military expert who keenly watches the Russian military, Squadron Leader Vijainder K. Thakur (retd.), explained to EurAsian Times, “Kinzhal is not just a missile that you can shoot at the adversary. It needs a launch platform that is expensive and difficult to operate. It needs intelligence for targeting. North Korea does not have MiG-31D. Since the heavy fighter is not in production, it is very doubtful that Russia can transfer it to North Korea.”\n",
        "When it was pointed out that Russia is reportedly firing the Kinzhal from its Su-34 Fullback fighter bomber, Thakur retorted, “North Korea does not have Su 34. Russia has as yet not met its demand for its Su-34 frontline bomber. So, it is improbable.”\n",
        "The US has accused Kim of supplying weapons and ammunition, including shells and rockets, to support Putin’s conflict for months. Although the US claims that the guns won’t dramatically change the battlefield, they can still be used to shell Ukraine. More importantly, these sales could give North Korea a new source of income for a country whose economy is mainly cut off from international trade.\n",
        "Some officials in the US as well as South Korea have warned that any such deal would be in contravention of the UN sanctions and would come at a heavy price.\n",
        "Cutting-Edge Systems Shown To North Korean Leader\n",
        "The North Korean leader was also shown an array of cutting-edge warplanes, out of which its strategic supersonic bombers particularly stood out. Bombers like Tu-160, Tu-95, and Tu-22 bombers that have been extensively deployed to launch cruise missiles were presented to Kim Jong Un.\n",
        "In addition, Kim was informed by Shoigu and Lt. Gen. Sergei Kobylash that the Tu-160 had just acquired brand-new cruise missiles with a 4,040-mile range. Shoigu pointed to the weapons bay and stated that each bomber had 12 missiles.\n",
        "Besides the bombers, Kim also had the chance to see Russia’s fifth-generation stealth jet. The RuMoD noted that Kim also visited the Russian Marshal Shaposhnikov frigate to inspect the Su-35 and the Su-57 stealth combat fighter during a tour of a factory producing fighter jets and other aircraft types.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzTSEbwLF44U",
        "outputId": "50d8b6d9-a03c-4ebc-adb6-9c9a533ced44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kim Jong Un, during his visit to Russia, inspected state-of-the-art systems deployed in the ongoing Ukraine war, including the Kinzhal hypersonic missile, supersonic bombers, and the latest weapons mounted on the MiG-31 missile carrier, which was presented to him by Russian Defense Minister Sergei Shoigu at the Knevichi airfield near Vladivostok, sparking concerns in the West about a potential arms agreement between North Korea and Russia.\n"
          ]
        }
      ],
      "source": [
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e-Xz0LaGObG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_xtLoDINhff"
      },
      "source": [
        "## component 2: Ask for the output in a specific format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_SyczGobhw4",
        "outputId": "174b7562-8d3c-4548-a891-305a85c25d23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Animal   | Genus      | Species     |\n",
            "|----------|------------|-------------|\n",
            "| Lion     | Panthera   | leo         |\n",
            "| Elephant | Loxodonta  | africana    |\n",
            "| Tiger    | Panthera   | tigris      |\n",
            "| Giraffe  | Giraffa    | camelopardalis |\n",
            "| Zebra    | Equus      | zebra       |\n",
            "| Gorilla  | Gorilla    | gorilla     |\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"Write a table in markdown with 6 animals in it, with their genus and species\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV-WtC6DNnTf"
      },
      "outputs": [],
      "source": [
        "# Task , format\n",
        "prompt = f\"\"\"\n",
        "Generate a list of 10 job titles related to Analytics and Software Engineering along with important skills and tools used.\n",
        "provide them in JSON format with the following  keys:\n",
        "job_id, job_title, job_skills, job_tools\n",
        "\"\"\"\n",
        "response = generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtxu5SY5OXEx",
        "outputId": "13ecfa29-738b-47a8-82c4-220d6a8929d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"jobs\": [\n",
            "    {\n",
            "      \"job_id\": 1,\n",
            "      \"job_title\": \"Data Analyst\",\n",
            "      \"job_skills\": [\"Statistical analysis\", \"Data visualization\", \"SQL\"],\n",
            "      \"job_tools\": [\"Tableau\", \"Power BI\", \"Python\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 2,\n",
            "      \"job_title\": \"Business Intelligence Developer\",\n",
            "      \"job_skills\": [\"ETL processes\", \"Data warehousing\", \"Data modeling\"],\n",
            "      \"job_tools\": [\"Microsoft SQL Server\", \"Oracle BI\", \"Informatica\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 3,\n",
            "      \"job_title\": \"Machine Learning Engineer\",\n",
            "      \"job_skills\": [\"Python programming\", \"Deep learning\", \"Natural language processing\"],\n",
            "      \"job_tools\": [\"TensorFlow\", \"Keras\", \"PyTorch\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 4,\n",
            "      \"job_title\": \"Data Scientist\",\n",
            "      \"job_skills\": [\"Predictive modeling\", \"Data mining\", \"Statistical analysis\"],\n",
            "      \"job_tools\": [\"R programming\", \"SAS\", \"Hadoop\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 5,\n",
            "      \"job_title\": \"Software Engineer\",\n",
            "      \"job_skills\": [\"Object-oriented programming\", \"Algorithm design\", \"Software testing\"],\n",
            "      \"job_tools\": [\"Java\", \"C++\", \"Git\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 6,\n",
            "      \"job_title\": \"DevOps Engineer\",\n",
            "      \"job_skills\": [\"Continuous integration/continuous deployment (CI/CD)\", \"Infrastructure as code\", \"Containerization\"],\n",
            "      \"job_tools\": [\"Docker\", \"Kubernetes\", \"Jenkins\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 7,\n",
            "      \"job_title\": \"Data Engineer\",\n",
            "      \"job_skills\": [\"Data pipeline development\", \"Database management\", \"Big data technologies\"],\n",
            "      \"job_tools\": [\"Apache Spark\", \"Hive\", \"Apache Kafka\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 8,\n",
            "      \"job_title\": \"Quantitative Analyst\",\n",
            "      \"job_skills\": [\"Financial modeling\", \"Risk management\", \"Time series analysis\"],\n",
            "      \"job_tools\": [\"Matlab\", \"Bloomberg Terminal\", \"QuantLib\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 9,\n",
            "      \"job_title\": \"Full Stack Developer\",\n",
            "      \"job_skills\": [\"Front-end development\", \"Back-end development\", \"Database management\"],\n",
            "      \"job_tools\": [\"JavaScript\", \"Node.js\", \"MongoDB\"]\n",
            "    },\n",
            "    {\n",
            "      \"job_id\": 10,\n",
            "      \"job_title\": \"Data Architect\",\n",
            "      \"job_skills\": [\"Data modeling\", \"Database design\", \"Data governance\"],\n",
            "      \"job_tools\": [\"Microsoft SQL Server\", \"Oracle Database\", \"Erwin\"]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnp0q_V0OZvQ"
      },
      "outputs": [],
      "source": [
        "# Task , format\n",
        "prompt = f\"\"\"\n",
        "Generate a list of 10 job titles related to Analytics and Software Engineering along with important skills and tools used.\n",
        "provide them in CSV format with the following headers:\n",
        "job_id, job_title, job_skills, job_tools\n",
        "\"\"\"\n",
        "response = generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITVZTujKOswJ",
        "outputId": "bca8ef6a-5b65-43fc-f05d-e32ab777a91d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "job_id, job_title, job_skills, job_tools\n",
            "1, Data Analyst, SQL, Python, R, Tableau, Power BI, Excel, Statistical Analysis, Data Visualization\n",
            "2, Business Intelligence Developer, SQL, ETL, Data Warehousing, Tableau, Power BI, SSIS, SSRS, Data Modeling\n",
            "3, Data Scientist, Python, R, Machine Learning, Statistical Analysis, Data Visualization, Hadoop, Spark, TensorFlow\n",
            "4, Software Engineer, Java, C++, Python, JavaScript, HTML/CSS, Git, Agile Development, DevOps\n",
            "5, Machine Learning Engineer, Python, R, Machine Learning, Deep Learning, TensorFlow, PyTorch, Scikit-learn\n",
            "6, Data Engineer, SQL, ETL, Data Warehousing, Python, Hadoop, Spark, Kafka, Airflow\n",
            "7, Analytics Manager, SQL, Python, R, Tableau, Power BI, Statistical Analysis, Data Visualization, Team Management\n",
            "8, Full Stack Developer, JavaScript, Node.js, React, Angular, HTML/CSS, MongoDB, Express, Git\n",
            "9, Data Architect, SQL, Data Modeling, ETL, Data Warehousing, Hadoop, Spark, NoSQL databases\n",
            "10, Business Analyst, SQL, Excel, Tableau, Power BI, Data Analysis, Requirements Gathering, Process Improvement\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loIN5Ys_OtnB"
      },
      "outputs": [],
      "source": [
        "# Task , format, constraint\n",
        "prompt = f\"\"\"\n",
        "Generate a list of 10 job titles related to Analytics and Software Engineering along with important skills and tools used.\n",
        "provide them in CSV format with the following headers:\n",
        "job_id, job_title, job_skills, job_tools\n",
        "In a single column such as job_skills and job_tools, keep multiple values separated by a semicolon.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NFwrZ0hPbqD",
        "outputId": "e0ff9dfa-83a3-4776-adda-9002ee0dc7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "job_id, job_title, job_skills, job_tools\n",
            "1, Data Analyst, SQL; Python; Data Visualization; Statistical Analysis, Tableau; Power BI; Excel\n",
            "2, Business Intelligence Developer, ETL; Data Warehousing; SQL; Data Modeling, Informatica; Microsoft SQL Server; Oracle\n",
            "3, Machine Learning Engineer, Python; R; Deep Learning; Natural Language Processing, TensorFlow; PyTorch; Keras\n",
            "4, Data Scientist, Machine Learning; Statistical Analysis; Python; R, Jupyter Notebook; SAS; MATLAB\n",
            "5, Software Engineer, Java; C++; Agile Development; Object-Oriented Programming, Git; JIRA; Jenkins\n",
            "6, Data Engineer, ETL; SQL; Data Warehousing; Python, Apache Spark; Hadoop; Kafka\n",
            "7, Big Data Engineer, Hadoop; Spark; NoSQL; SQL, Apache HBase; Cassandra; MongoDB\n",
            "8, DevOps Engineer, Linux; Docker; Kubernetes; CI/CD, Ansible; Jenkins; GitLab\n",
            "9, Cloud Solutions Architect, AWS; Azure; Google Cloud Platform; Infrastructure as Code, Terraform; CloudFormation; Chef\n",
            "10, Full Stack Developer, JavaScript; HTML/CSS; Node.js; React, MongoDB; Express.js; AngularJS\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLt0pk3APfps"
      },
      "outputs": [],
      "source": [
        "with open(\"job_data.csv\",'w') as file:\n",
        "  file.write(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1fNlBgbP1kR",
        "outputId": "4fe05984-06c9-4905-ef3e-d167cc5abdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Get some warm water and mix it with detergent.\n",
            "Step 2: Put the dirty clothes in the water and let them soak for some time.\n",
            "Step 3: Remove the clothes from the water and rub any remaining stains with a soft brush.\n",
            "Step 4: Rinse the clothes to remove the detergent.\n",
            "Step 5: Hang the clothes to dry on a rope.\n",
            "Step 6: Enjoy your clean clothes!\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-I0CzPKTyfd",
        "outputId": "4fa014ff-8eea-426c-eaf3-e5b36e5932c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Observe the morning weather and the sun's appearance between the clouds.\n",
            "Step 2: Take note of the pleasant weather and the mind-blowing wind.\n",
            "Step 3: Appreciate the overall experience of the day.\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTuKaTEeUVWE",
        "outputId": "74820bc0-b751-4970-ae72-aab9749e7a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: First you need to get some warm water.\n",
            "Step 2: Mix the warm water with some detergent.\n",
            "Step 3: Put the dirty clothes in it and let it stay wet for some time.\n",
            "Step 4: Take clothes out and rub the dirt/stains with a soft brush to remove the stains if any.\n",
            "Step 5: Get the clothes mixed with water to get the detergent out of it.\n",
            "Step 6: Put it for drying on a rope.\n",
            "Step 7: Enjoy the clean clothes.\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAZGUBpTUrgv",
        "outputId": "abf6a8f9-c40a-4847-d591-3ed225417f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No steps provided\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6osQJS0czIu-"
      },
      "source": [
        "### Component: ALlow the model to process the outcome progressively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGtXe-NfwsW0",
        "outputId": "d50374ed-a3a1-44d1-a38d-a7187b316694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Morning is amazing, sun is bright, weather is pleasant, wind is mindblowing. Loving the day.\n",
            "French: Matin incroyable, soleil brillant, temps agréable, vent époustouflant. J'aime la journée.\n",
            "JSON Output:\n",
            "{\n",
            "  \"morning\": \"incroyable\",\n",
            "  \"sun\": \"brillant\",\n",
            "  \"weather\": \"agréable\",\n",
            "  \"wind\": \"époustouflant\",\n",
            "  \"enjoying\": \"journée\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\" summarize the below text in 15 words, translate to french and list each name in the french summary, also createa json output.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic51u_OxzGQN",
        "outputId": "4a83a278-2d43-4e94-8ca7-542dbf0ed887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Morning is amazing, sun bright, pleasant weather, mindblowing wind, loving day. Met Jenny, good time.\n",
            "2. Le matin est incroyable, soleil brillant, temps agréable, vent époustouflant, journée aimante. Jenny.\n",
            "3. Jenny\n",
            "4. {\n",
            "   \"french_summary\": \"Le matin est incroyable, soleil brillant, temps agréable, vent époustouflant, journée aimante. Jenny.\",\n",
            "   \"num_names\": 1\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "I met Jenny today and we spent good time.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Perform the following tasks:\n",
        "1. Summarize the following text delimited by triple backticks in 15 words.\n",
        "2. translate the summary to French\n",
        "3. LIst each name in the french summary\n",
        "4. Output a json object that contains the following keys: french_summary, num_names.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1WZs8Lg0SlZ",
        "outputId": "194c36f1-90b9-4382-9d37-9e2b00887b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Beautiful morning, pleasant weather, met Jenny, enjoyed the day.\n",
            "Translation: Belle matinée, temps agréable, rencontré Jenny, apprécié la journée.\n",
            "Names: Jenny\n",
            "Output JSON: {\"french_summary\": \"Belle matinée, temps agréable, rencontré Jenny, apprécié la journée\", \"num_names\": 1}\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "THe morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing. on a whole i am loving the day today.\n",
        "I met Jenny today and we spent good time.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Perform the following tasks:\n",
        "1. Summarize the following text delimited by <> in 15 words.\n",
        "2. translate the summary to French\n",
        "3. LIst each name in the french summary\n",
        "4. Output a json object that contains the following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text: <text to summarize>\n",
        "Summary: <summary >\n",
        "Tranlation: <Summary translation>\n",
        "Names: <list of names>\n",
        "Output JSON: <json with summary and num_names>\n",
        "\n",
        "Text:\n",
        "<{text}>\n",
        "\"\"\"\n",
        "\n",
        "response = generate_response(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BP-Z6_8m0w2t",
        "outputId": "92424385-b5e6-4da2-8b00-d7eeb6a88a8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'True + True = True\\n\\nIn boolean logic, the addition of two true values results in a true value. Therefore, the expression True + True equals True.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Evaluate the following expression considering boolean logic (All Values are in boolean):\n",
        "  True + True = True\n",
        "\"\"\"\n",
        "generate_response(prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1xrQNg0br00"
      },
      "source": [
        "## Zero Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DpqkFzDvsTe",
        "outputId": "30f2f708-a2f1-4b65-d63b-c0afdb39418a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Child: Grandma, can you tell me a story from when you were a little girl?\n",
            "\n",
            "Grandma: Of course, sweetie. Let me tell you about the time when I was your age and I went on a big adventure with my friends.\n",
            "\n",
            "Child: Wow, that sounds exciting! What happened?\n",
            "\n",
            "Grandma: Well, we decided to explore the woods behind our house. We packed some snacks and set off on our adventure. We saw so many beautiful trees and flowers, and we even found a little stream to play in.\n",
            "\n",
            "Child: That sounds like so much fun! Did anything scary happen?\n",
            "\n",
            "Grandma: Oh yes, there was a moment when we got a little lost and started to panic. But then we remembered to stay calm and follow the sun to find our way back home.\n",
            "\n",
            "Child: That's so brave, Grandma! I wish I could have been there with you.\n",
            "\n",
            "Grandma: I'm sure you would have loved it, sweetie. It was a day I'll never forget. And it's important to always be safe and have fun when you go on adventures.\n",
            "\n",
            "Child: I'll remember that, Grandma. Thanks for sharing your story with me.\n",
            "\n",
            "Grandma: You're welcome, my dear. I love sharing my memories with you.\n"
          ]
        }
      ],
      "source": [
        "# zero shot prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Create a conversation story between child and grandparent.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBE11_6vwJd"
      },
      "source": [
        "## Few Shot Prompting\n",
        "\n",
        "Here, the model is given a few examples (shots) to guide its response. By providing context or previous instances, the model can better understand and generate the desired output. For example, showing a model several examples of translated sentences before asking it to translate a new one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SurLNqfa6wi",
        "outputId": "49d821fb-5add-4b67-c386-11b7eac04d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<grandma>: Resilience is like a tree standing tall and strong, even after enduring strong winds and storms. It's the ability to bounce back and keep growing, no matter what challenges come your way.\n"
          ]
        }
      ],
      "source": [
        "# few shot prompting\n",
        "prompt = f\"\"\"\n",
        "your task is to answer in a consistent sytle:\n",
        "\n",
        "<child>: Teach me about patience.\n",
        "<grandma>: Patience is like waiting for whole day to see the moon in the evening and then sleeping after having a look at it.\n",
        "\n",
        "<child>: Teach me about resilience.\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtJ2ipJbhw6"
      },
      "source": [
        "#### Few shot prompting with role setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTawSemLbhw6",
        "outputId": "5c74e664-f713-4f6c-a397-31befc3dc811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9azDaViB8e0VmdMAZBm5qtvFvhJIW\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"positive\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1718602158,\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": \"fp_811936bd4f\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 1,\n",
            "    \"prompt_tokens\": 66,\n",
            "    \"total_tokens\": 67\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "result = client.chat.completions.create(\n",
        "    model=deployment_name,  # e.g. gpt-35-instant\n",
        "    max_tokens=200,\n",
        "    temperature=0.9,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was an awesome experience\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"positive\"},\n",
        "        {\"role\": \"user\", \"content\": \"I won't do that again\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"That was not worth my time\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
        "        {\"role\": \"user\", \"content\": \"You can't miss this\"}\n",
        "    ],\n",
        ")\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IBIItcqbhw_"
      },
      "source": [
        "## Chain of Thought Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbMnOeiq2atC",
        "outputId": "2c393816-7d72-4017-cf8b-7fcfffc12439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11 pens\n"
          ]
        }
      ],
      "source": [
        "# Without Chain of Thought Prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7Hz_cvLbhw_",
        "outputId": "395b67bf-6e04-4ab1-b4cf-90128382bb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Marry had 5 pens, gave 3 away = 5 - 3 = 2 pens\n",
            "Then she bought 2 boxes with 3 pens each = 2 + 2*3 = 8 pens now\n"
          ]
        }
      ],
      "source": [
        "# with Chain of Thought prompting\n",
        "prompt = f\"\"\"\n",
        "\n",
        "Teacher: Johan had 5 apples, he bought 4 more boxes with 5 apples each. How many apples does he have now?\n",
        "Student: Johan had 5 apples, 4 boxes with 5 apples each = 5 + 4*5 = 25 apples\n",
        "\n",
        "Teacher: Marry had 5 pens, she gave 3 to her friend. and bought 2 boxes of pen with 3 pen in each box. How many pens does she have now?\n",
        "Student:\n",
        "\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQvoNRxqVo5_"
      },
      "source": [
        "## Tree of Thoughts (ToT)\n",
        "\n",
        "Tree of Thoughts (ToT) prompting is a framework that generalizes over chain-of-thought prompting and encourages exploration over thoughts that serve as intermediate steps for general problem-solving with language models.\n",
        "\n",
        "\n",
        "How does it work?\n",
        "\n",
        "- ToT prompting breaks problems down into smaller parts, similar to CoT prompting, but goes further by combining this with the ability to explore multiple solution paths in parallel, forming a tree instead of a single chain. Each thought is generated or solved independently and passed to the next step, allowing the model to self-evaluate and decide whether to continue with that path or choose another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF7_WBM9MT78",
        "outputId": "464c31d5-8d16-4638-d2ec-d486952f6ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert 1: The most likely location of the watch is at the poolside lounger, where Carlos opened and vigorously shook the towel.\n",
            "\n",
            "Expert 2: I agree with Expert 1. It makes sense that if Carlos lost his watch, it would have been during the vigorous shaking of the towel at the poolside lounger.\n",
            "\n",
            "Expert 3: I disagree. I think the most likely location of the watch is at the snack bar. Carlos left the towel there, so it's possible that the watch fell out when he left it there.\n",
            "\n",
            "Expert 4: I see your point, Expert 3, but I still think the poolside lounger is the most likely location. The vigorous shaking of the towel would have increased the chances of the watch falling out.\n",
            "\n",
            "Expert 5: I'm not sure. It could also be possible that the watch fell out while Carlos was walking from the pool to the locker room. We shouldn't discount that possibility.\n",
            "\n",
            "Expert 1: You're right, Expert 5. We need to consider all possibilities. Let's think this through again.\n",
            "\n",
            "Expert 2: I agree. We need to carefully consider each step and the likelihood of the watch being lost at each location.\n",
            "\n",
            "Expert 3: I still think the snack bar is the most likely location, but I'm open to reconsidering.\n",
            "\n",
            "Expert 4: I'm still leaning towards the poolside lounger, but I see the merit in considering the other locations as well.\n",
            "\n",
            "Expert 5: I think we need to go back and carefully analyze each step to determine the most likely location of the watch.\n",
            "\n",
            "Expert 1: Agreed. Let's carefully consider each step and the likelihood of the watch being lost at each location.\n",
            "\n",
            "Expert 2: I think we need to reassess the likelihood of the watch being lost at each step. We can't make any assumptions without considering all the possibilities.\n",
            "\n",
            "Expert 3: I agree. We need to carefully evaluate each step and the likelihood of the watch being lost at each location.\n",
            "\n",
            "Expert 4: I still think the poolside lounger is the most likely location, but I'm open to reconsidering based on the evidence.\n",
            "\n",
            "Expert 5: I think we need to carefully consider the likelihood of the watch being lost at each step before coming to a conclusion.\n",
            "\n",
            "Expert 1: I agree. We need to carefully evaluate the likelihood of the watch being lost at each step before reaching a conclusion.\n",
            "\n",
            "Expert 2: I think we need to carefully consider the evidence and the likelihood of the watch being lost at each location before coming to a final conclusion.\n",
            "\n",
            "Expert 3: I still think the snack bar is the most likely location, but I'm open to reconsidering based on the evidence.\n",
            "\n",
            "Expert 4: I still think the poolside lounger is the most likely location, but I'm open to reconsidering based on the evidence.\n",
            "\n",
            "Expert 5: I think we need to carefully consider the likelihood of the watch being lost at each step before coming to a conclusion.\n",
            "\n",
            "Expert 1: I agree. We need to carefully evaluate the likelihood of the watch being lost at each step before reaching a conclusion.\n",
            "\n",
            "After careful consideration and evaluation of the evidence, the experts agree that the most likely location of the lost watch is at the poolside lounger, where Carlos opened and vigorously shook the towel.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = \"\"\"\n",
        "Imagine 5 different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is.\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPnsQc3hpQ7x"
      },
      "source": [
        "## Chain-of-Verification Prompting\n",
        "\n",
        "The Chain-of-Verification (CoVe) prompt engineering method aims to reduce hallucinations through a verification loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9mjZtAJfDdm",
        "outputId": "02fd7f2f-0807-4f97-a922-150203852bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Some athletes who were born in the United States include Michael Jordan, Serena Williams, and Tom Brady.\n",
            "\n",
            "Verification 1: Was Michael Jordan born in the United States?\n",
            "Verification 1 response: Yes, Michael Jordan was born in Brooklyn, New York.\n",
            "\n",
            "Verification 2: Was Serena Williams born in the United States?\n",
            "Verification 2 response: Yes, Serena Williams was born in Saginaw, Michigan.\n",
            "\n",
            "Verification 3: Was Tom Brady born in the United States?\n",
            "Verification 3 response: Yes, Tom Brady was born in San Mateo, California.\n",
            "\n",
            "Final, verified response: Some athletes who were born in the United States include Michael Jordan, Serena Williams, and Tom Brady.\n"
          ]
        }
      ],
      "source": [
        "Question=\"Name some athletes who were born in United states\"\n",
        "\n",
        "prompt=f'''Here is the question: {Question}.\n",
        "\n",
        "First, generate a response.\n",
        "\n",
        "Then, create and answer verification questions based on this response to check for accuracy. Think it through and make sure you are extremely accurate based on the question asked.\n",
        "\n",
        "After answering each verification question, consider these answers and revise the initial response to formulate a final, verified answer. Ensure the final response reflects the accuracy and findings from the verification process.'''\n",
        "\n",
        "\n",
        "\n",
        "ans=generate_response(prompt)\n",
        "\n",
        "print(ans)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8_TNNG2Ozu6"
      },
      "source": [
        "# Model Limitations: Hallucinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Or9Q36oxO4bx",
        "outputId": "002944d7-7d3b-4f4c-e746-8618ceedefbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Amdocs IT Services produces and sells ergonomic chairs designed to provide maximum comfort and support for individuals who spend long hours sitting at a desk. These chairs are specifically engineered to promote good posture and reduce the risk of musculoskeletal issues such as back pain and neck strain.\\n\\nThe ergonomic chairs produced by Amdocs IT Services are adjustable, allowing users to customize the height, armrests, and lumbar support to their specific needs. The chairs also feature high-quality materials and cushioning to ensure durability and long-term comfort.\\n\\nAmdocs IT Services prioritizes the health and well-being of its customers, and their ergonomic chairs are designed with this in mind. Whether for use in an office setting or for remote work, Amdocs IT Services' ergonomic chairs are a popular choice for individuals seeking a comfortable and supportive seating solution.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ergonamic chair procuced and sold by Amdocs IT Services.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "n4rvOOeSPIDV",
        "outputId": "40fcd47c-5e5f-4a6f-e494-e46156ea7213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I\\'m sorry, but I couldn\\'t find any information about an \"Ergonamic Toothbrush\" by Amdocs. It\\'s possible that this product does not exist or that it is not widely known. Amdocs is a software and services provider for communications, media, and entertainment industries, so it\\'s unlikely that they would be involved in the production of a toothbrush. If you have any other questions or need information on a different topic, feel free to ask!'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ergonamic Toothbrush by Amdocs.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "hzawWC-7PT_l",
        "outputId": "b37b23b3-67f3-49d8-f02f-a041bc823c31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The Ultraslim Toothbrush by Spectrum is a high-quality toothbrush designed to provide a thorough and effective cleaning experience. It features an ultra-slim design with soft bristles that are gentle on the gums and teeth, making it ideal for those with sensitive mouths.\\n\\nThe toothbrush is designed with a compact head that allows for easy access to hard-to-reach areas in the mouth, ensuring a comprehensive cleaning experience. The slim handle provides a comfortable grip, making it easy to maneuver and control while brushing.\\n\\nThe Ultraslim Toothbrush is available in a variety of colors, allowing users to choose their preferred option. It is a great option for those looking for a reliable and efficient toothbrush that is gentle on the mouth while still providing a thorough cleaning experience.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about Ultraslim Toothbrush by Spectrum.\n",
        "\"\"\"\n",
        "\n",
        "generate_response(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjWPGpKzPdQB",
        "outputId": "bca16ba5-1720-49aa-dc89-eb1cfb636756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Manila - The bustling capital city of the Philippines known for its vibrant culture and historical landmarks.\n",
            "2. Delhi - The bustling capital city of India, known for its rich history, diverse culture, and bustling markets.\n",
            "3. Amdocsonia - A fictional city with no known characteristics or attributes.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate one line description for each of the following city:\n",
        "1. Manila\n",
        "2. Delhi\n",
        "3. Amdocsonia\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io6r-CoeRP5r",
        "outputId": "5f2f3dc9-e61f-44a7-e578-ca5a85825631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Manila - The capital city of the Philippines known for its vibrant culture and historical landmarks.\n",
            "2. Delhi - The capital city of India, famous for its rich history, diverse culture, and bustling markets.\n",
            "3. spectrumania - No description can be generated as this city does not exist.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Generate one line description for each of the following city, check if the city exists, if it does not exist, say no description can be generated:\n",
        "1. Manila\n",
        "2. Delhi\n",
        "3. spectrumania\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-DmK07y94x8"
      },
      "source": [
        "## Conversational App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lap6MZ-ARdKd"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(messages,model=deployment_name):\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=0.5\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgHXbLb0bhxA",
        "outputId": "1dddbf0c-edcd-4ee2-e6cc-77398101967b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:  hi\n",
            "Bot: Hello! How can I assist you today?\n",
            "You:  how are you\n",
            "Bot: I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with any questions or tasks you have! How can I assist you today?\n",
            "You:  tell me joke\n",
            "Bot: Sure, here's a joke for you:\n",
            "\n",
            "Why don't skeletons fight each other?\n",
            "\n",
            "They don't have the guts!\n",
            "You:  q\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},]\n",
        "while True:\n",
        "    uinput = input(\"You: \")\n",
        "    print(\"You: \",uinput)\n",
        "    if uinput.lower() in ['q','quit','exit']:\n",
        "        break\n",
        "    messages.append({\"role\":\"user\",\"content\":uinput})\n",
        "    response = generate_response(messages=messages)\n",
        "    print(f\"Bot: {response}\")\n",
        "    messages.append({\"role\":\"assistant\",\"content\":response})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WErsqIf94x9"
      },
      "source": [
        "## Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}