{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOptNAZMRJdpfH9Opiym9bG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Generative-AI-for-Professionals/blob/main/Privacy_PrivateAI_VectorDB_chroma_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHhpYCLo1WDI",
        "outputId": "f7d72543-0ee5-4642-83cb-155760be608c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.7/521.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyPDF openai langchain langchain-openai privateai_client chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "PAI_API_KEY = \"79f184171e5d4d6b85f1e86c255d36d1\""
      ],
      "metadata": {
        "id": "t8M-Xu9C1W5b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from privateai_client import PAIClient\n",
        "from privateai_client import request_objects\n",
        "\n",
        "# Adding credentials on initialization\n",
        "client = PAIClient(url=\"https://api.private-ai.com/deid/\", api_key=PAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2tl5c1_4ESB",
        "outputId": "bc0c1156-5429-41c9-832f-91b1b8d3e3dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My sample name is John Smith']\n",
            "['My sample name is [NAME_1]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "E8EZfQq21m0P"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d3B9BlOk6rnt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_paths = [\"Case Studies.pdf\",]\n",
        "#path: https://github.com/anshupandey/Generative-AI-for-Professionals/blob/main/Data/Case%20Studies.pdf\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loaders = [PyPDFLoader(pdf, extract_images=False) for pdf in doc_paths]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    doc = loader.load()\n",
        "    docs.extend(doc)\n",
        "\n",
        "print(f\"Loaded  {len(docs)} documents from PDF files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YAFovqN5fa4",
        "outputId": "0742b220-097a-4ef0-bc96-c63aa399044e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded  12 documents from PDF files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=docs, embedding=OpenAIEmbeddings())\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
        "\n",
        "retrieved_docs = retriever.invoke(\"How to use LangChain to develop enterprise solutions?\")"
      ],
      "metadata": {
        "id": "lfg6OunR6Gy6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in retrieved_docs:print(doc.page_content,\"\\n**********\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaIDJnPs7-o7",
        "outputId": "1d46399c-be4b-42a2-a877-3d1105858841"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing Supply Chain for EcoBuild Materials  \n",
            "Title:  \n",
            "Transforming Supply Chain Management with AI: Jessica Lee's Initiative at EcoBuild Materials  \n",
            " \n",
            "Introduction:  \n",
            "Jessica Lee, a supply chain analyst at EcoBuild Materials, was tasked with finding a solution \n",
            "to optimize the company's supply chain for sustainability and efficiency.  \n",
            " \n",
            "Challenge:  \n",
            "EcoBuild Materials, a company specializing in eco -friendly construction materials, faced \n",
            "challenges in managing its complex supply chain, which impacted its sustainability goals and \n",
            "operational efficiency.  \n",
            " \n",
            "Solution:  \n",
            "Jessica discovered LangChain and saw its potential to harness Cohere's LLMs for developing \n",
            "an AI -driven solution to optimize supply chain decisions, reduce waste, and improve material \n",
            "sourcing.  \n",
            " \n",
            "Implementation:  \n",
            "Step 1: She integrated LangChain with Cohere's LLMs to analyze supply chain data and \n",
            "predict demand more accurately.  \n",
            "Step 2: Jessica developed algorithms to identify the most eco -friendly and cost -effective \n",
            "routes and suppliers.  \n",
            "Step 3: She also implemented a system for real -time inventory management, reducing \n",
            "overstock and minimizing waste.  \n",
            " \n",
            "Outcome:  \n",
            "Jessica Lee's initiative significantly improved EcoBuild Materials' supply chain efficiency and \n",
            "sustainability. The AI -driven tools she developed using LangChain and Cohere's LLMs \n",
            "enabled smarter decision -making, reducing costs, and enhancing the company's  \n",
            "commitment to sustainability.  \n",
            " \n",
            "   \n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in retrieved_docs:\n",
        "  text_request = request_objects.process_text_obj(text=[doc.page_content])\n",
        "  response = client.process_text(text_request)\n",
        "  print(response.processed_text[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4qBX3VJ8O-Q",
        "outputId": "064e6cd9-19bd-47af-ed38-b829b5449087"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing Supply Chain for [ORGANIZATION_1]  \n",
            "Title:  \n",
            "Transforming Supply Chain Management with AI: [NAME_1]'s Initiative at [ORGANIZATION_1]  \n",
            " \n",
            "Introduction:  \n",
            "[NAME_1], a [OCCUPATION_1] at [ORGANIZATION_1], was tasked with finding a solution \n",
            "to optimize the company's supply chain for sustainability and efficiency.  \n",
            " \n",
            "Challenge:  \n",
            "[ORGANIZATION_1], a company specializing in eco -friendly construction materials, faced \n",
            "challenges in managing its complex supply chain, which impacted its sustainability goals and \n",
            "operational efficiency.  \n",
            " \n",
            "Solution:  \n",
            "[NAME_GIVEN_1] discovered [ORGANIZATION_2] and saw its potential to harness [ORGANIZATION_3]'s LLMs for developing \n",
            "an AI -driven solution to optimize supply chain decisions, reduce waste, and improve material \n",
            "sourcing.  \n",
            " \n",
            "Implementation:  \n",
            "Step 1: She integrated LangChain with [ORGANIZATION_3]'s LLMs to analyze supply chain data and \n",
            "predict demand more accurately.  \n",
            "Step 2: [NAME_GIVEN_1] developed algorithms to identify the most eco -friendly and cost -effective \n",
            "routes and suppliers.  \n",
            "Step 3: She also implemented a system for real -time inventory management, reducing \n",
            "overstock and minimizing waste.  \n",
            " \n",
            "Outcome:  \n",
            "[NAME_1]'s initiative significantly improved [ORGANIZATION_1]' supply chain efficiency and \n",
            "sustainability. The AI -driven tools she developed using [ORGANIZATION_2] and [ORGANIZATION_3]'s LLMs \n",
            "enabled smarter decision -making, reducing costs, and enhancing the company's  \n",
            "commitment to sustainability.  \n",
            " \n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OviXs34x8q3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}